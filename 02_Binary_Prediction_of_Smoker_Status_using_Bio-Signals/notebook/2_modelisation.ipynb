{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "902d3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "# ^^^ pyforest auto-imports - don't write above this line\n",
    "import pyforest\n",
    "import os\n",
    "import warnings\n",
    "import sklearn\n",
    "\n",
    "#preparation des données\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "#modeles :\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#mesure performance : \n",
    "from sklearn import metrics\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c050d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:',\n",
       " 'etude_data_science',\n",
       " 'Kaggle_competition',\n",
       " '02_Binary_Prediction_of_Smoker_Status_using_Bio-Signals',\n",
       " 'notebook']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture des données :\n",
    "path1 = [i for i in os.getcwd().split(\"\\\\\")]\n",
    "path1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a88cb63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = (\"\\\\\").join(path1[:-1]) + \"\\\\dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e83b054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_cleaned.csv',\n",
       " 'playground-series-s3e24.zip',\n",
       " 'sample_submission.csv',\n",
       " 'test.csv',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb14704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>dental caries</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.606746</td>\n",
       "      <td>0.755803</td>\n",
       "      <td>-1.218238</td>\n",
       "      <td>-0.401488</td>\n",
       "      <td>-0.427850</td>\n",
       "      <td>-0.212524</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.772676</td>\n",
       "      <td>-1.172399</td>\n",
       "      <td>0.307489</td>\n",
       "      <td>-0.006818</td>\n",
       "      <td>0.700179</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.181505</td>\n",
       "      <td>4.401603</td>\n",
       "      <td>-2.490884</td>\n",
       "      <td>-1.117876</td>\n",
       "      <td>0.384461</td>\n",
       "      <td>3.960486</td>\n",
       "      <td>-6.225314</td>\n",
       "      <td>2.274480</td>\n",
       "      <td>-1.635772</td>\n",
       "      <td>3.977569</td>\n",
       "      <td>0.548055</td>\n",
       "      <td>1.063149</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.731105</td>\n",
       "      <td>-1.048645</td>\n",
       "      <td>-0.828711</td>\n",
       "      <td>0.055921</td>\n",
       "      <td>0.090602</td>\n",
       "      <td>1.316630</td>\n",
       "      <td>1.122125</td>\n",
       "      <td>0.630216</td>\n",
       "      <td>0.379617</td>\n",
       "      <td>-0.711981</td>\n",
       "      <td>0.085530</td>\n",
       "      <td>0.998121</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.369274</td>\n",
       "      <td>1.904712</td>\n",
       "      <td>0.788166</td>\n",
       "      <td>-1.374263</td>\n",
       "      <td>-0.530577</td>\n",
       "      <td>-0.646030</td>\n",
       "      <td>0.669578</td>\n",
       "      <td>0.086063</td>\n",
       "      <td>-0.155953</td>\n",
       "      <td>-0.352081</td>\n",
       "      <td>0.210692</td>\n",
       "      <td>0.889490</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.614225</td>\n",
       "      <td>-1.958460</td>\n",
       "      <td>-0.953814</td>\n",
       "      <td>-0.379936</td>\n",
       "      <td>0.165742</td>\n",
       "      <td>-0.792837</td>\n",
       "      <td>1.132931</td>\n",
       "      <td>1.293741</td>\n",
       "      <td>-0.738215</td>\n",
       "      <td>-0.599433</td>\n",
       "      <td>0.329744</td>\n",
       "      <td>-0.559030</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         F1        F2        F3        F4        F5        F6        F7  \\\n",
       "0 -3.606746  0.755803 -1.218238 -0.401488 -0.427850 -0.212524  0.734177   \n",
       "1 -1.181505  4.401603 -2.490884 -1.117876  0.384461  3.960486 -6.225314   \n",
       "2 -2.731105 -1.048645 -0.828711  0.055921  0.090602  1.316630  1.122125   \n",
       "3 -1.369274  1.904712  0.788166 -1.374263 -0.530577 -0.646030  0.669578   \n",
       "4  1.614225 -1.958460 -0.953814 -0.379936  0.165742 -0.792837  1.132931   \n",
       "\n",
       "         F8        F9       F10       F11       F12  hearing(left)  \\\n",
       "0  0.772676 -1.172399  0.307489 -0.006818  0.700179              1   \n",
       "1  2.274480 -1.635772  3.977569  0.548055  1.063149              2   \n",
       "2  0.630216  0.379617 -0.711981  0.085530  0.998121              1   \n",
       "3  0.086063 -0.155953 -0.352081  0.210692  0.889490              1   \n",
       "4  1.293741 -0.738215 -0.599433  0.329744 -0.559030              1   \n",
       "\n",
       "   hearing(right)  Urine protein  dental caries  smoking  \n",
       "0               1              1              0        1  \n",
       "1               2              1              1        0  \n",
       "2               1              1              0        1  \n",
       "3               1              1              1        0  \n",
       "4               1              1              0        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path2+\"\\\\data_cleaned.csv\", index_col = 0)\n",
    "df = data.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85eda4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération d'un sample du dataframe pour effectuer les différents test de modélisation\n",
    "\n",
    "#La colonne sera ensuite mute une fois les tests terminés pour utiliser l'ensemble du dataframe\n",
    "df = df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc56c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df.drop(\"smoking\", axis = 1), df[\"smoking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70917642",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train, y_test = train_test_split(X,y, random_state=42,\n",
    "                                                 test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661f0649",
   "metadata": {},
   "source": [
    "# Plan : \n",
    "\n",
    "## 1. Création de fonction de modélisation et  Préparation des modèles\n",
    "\n",
    "## 2. Entrainement des modèles\n",
    "\n",
    "## 3. Resultats\n",
    "\n",
    "## 4. Selection des modèles et amélioration par GridSearchCV\n",
    "\n",
    "## 5. Visualisation des performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9152d739",
   "metadata": {},
   "source": [
    "# 1. Création des fonctions de modélisation et préparation des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54c9b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model = [DummyClassifier(),\n",
    "             LogisticRegression(),\n",
    "             KNeighborsClassifier(),\n",
    "             SGDClassifier(),\n",
    "             SVC(),\n",
    "             RandomForestClassifier()\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7f3513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Création d'une fonction d'entrainement pour un modèle donné\n",
    "\n",
    "def train_model(model):\n",
    "    \"\"\"le modèle sera entrainé par validation score sur 5 split\n",
    "    et affichage du score moyen.\n",
    "    la fonction renvoi les prédiction du modèle entrainé\"\"\"\n",
    "    scores = (cross_val_score(estimator=model, X=X_train,y=y_train, cv=5)).mean()\n",
    "    print(\"Score moyen validation croisée :\", scores.round(2))\n",
    "    model.fit(X_train,y_train)\n",
    "    yp = model.predict(X_test)\n",
    "    return yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "963ec947",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Création d'une fonction qui renvoi l'ensemble des metrics :\n",
    "\n",
    "def metric(prediction, model_name):\n",
    "    \"\"\"Fonction qui renvoi un dataframe contenant les valeurs des metrics\n",
    "    principales : f1score, accuracy, recall et precision score\n",
    "    à partir de la liste des prédictions d'un modèle\"\"\"\n",
    "    \n",
    "    f1 = metrics.f1_score(y_true = y_test, y_pred = prediction)\n",
    "    accuracy = metrics.accuracy_score(y_true = y_test, y_pred = prediction)\n",
    "    recal = metrics.recall_score(y_true = y_test, y_pred = prediction)\n",
    "    precision = metrics.precision_score(y_true = y_test, y_pred = prediction)\n",
    "    all_metric = [f1,accuracy,recal,precision]\n",
    "    \n",
    "    index_metric = [\"F1\",\"accuracy\",\"recall\",\"precision\"]\n",
    "    \n",
    "    series = pd.Series(all_metric, name=str(model_name), index=index_metric)\n",
    "    return pd.DataFrame(series)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33e623ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fonction permettant de merge de dataframe :\n",
    "def merge(df1, df2):\n",
    "    return pd.merge(df1, df2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fonction pour créer une matrice de confusion : \n",
    "\n",
    "def matrice_confusion(prediction):\n",
    "    cf = metrics.confusion_matrix(y_true=y_test, y_pred=prediction)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    ax = sns.heatmap(cf, annot = True, linewidths=0.8, linecolor=\"black\", fmt = \".0f\",cbar=False, cmap = \"Blues\")\n",
    "    ax.set_xlabel('Prédictions')\n",
    "    ax.set_ylabel('Valeurs réelles')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e1ac59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fonction pour obtenir la learning curve d'un modèle : \n",
    "def learning_curv(model):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model,\n",
    "                                                                X_train, y_train, cv=5)\n",
    "    \n",
    "# Calcul des scores moyens pour l'apprentissage et la validation\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# Tracer les courbes d'apprentissage\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.plot(train_sizes, train_scores_mean, label='Score d\\'entraînement moyen')\n",
    "    plt.plot(train_sizes, test_scores_mean, label='Score de validation moyen')\n",
    "    plt.xlabel('Taille de l\\'ensemble d\\'entraînement')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Courbes d\\'apprentissage')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6229e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fonction pour obtenir la courbe ROC : \n",
    "\n",
    "def ROC(prediction):\n",
    "    FP_rate, TP_rate, thresholds = metrics.roc_curve(y_test,prediction)\n",
    "    roc_auc = metrics.auc(FP_rate,TP_rate)\n",
    "    print(\"ROC_AUC =\", roc_auc.round(2))\n",
    "    \n",
    "    \n",
    "    ### Création de la courbe AUC ROC :\n",
    "    plt.figure(figsize=(6,6))\n",
    "    \n",
    "    #Courbe prédictive :\n",
    "    sns.lineplot(x = FP_rate, y = TP_rate, color = \"orange\", label = f\"AUC = {roc_auc:,.2f}%\")\n",
    "    \n",
    "    #Courbe random :\n",
    "    sns.lineplot(x=[0,1],y=[0,1], linestyle = \"--\", c = \"r\", label= \"Random Classifier\")\n",
    "\n",
    "    plt.ylabel(\"True Positive rate\")\n",
    "    plt.xlabel(\"False Positive rate\")\n",
    "    plt.title(\"ROC\")\n",
    "    plt.legend(loc = \"upper left\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
