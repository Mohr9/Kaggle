{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63b205d",
   "metadata": {},
   "source": [
    "# Modélisation\n",
    "### Dans ce notebook nous allons suivre exactement la même stratégie que le notebook 2_modelisation en utililsant les données sans réduction par PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d62c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# ^^^ pyforest auto-imports - don't write above this line\n",
    "import pyforest\n",
    "import os\n",
    "import warnings\n",
    "import sklearn\n",
    "import time \n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#preparation des données\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "#modeles :\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#mesure performance : \n",
    "from sklearn import metrics\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e53baec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:',\n",
       " 'Etude_Data_science',\n",
       " 'Kaggle_competition',\n",
       " '02_Binary_Prediction_of_Smoker_Status_using_Bio-Signals',\n",
       " 'notebook']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture des données :\n",
    "path1 = [i for i in os.getcwd().split(\"\\\\\")]\n",
    "path1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb983d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = (\"\\\\\").join(path1[:-1]) + \"\\\\dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd349bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_cleaned.csv',\n",
       " 'data_cleaned_PCA.csv',\n",
       " 'data_cleaned_withoutPCA.csv',\n",
       " 'playground-series-s3e24.zip',\n",
       " 'sample_submission.csv',\n",
       " 'test.csv',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9cd3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>waist(cm)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>relaxation</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>...</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>serum creatinine</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>dental caries</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60700</th>\n",
       "      <td>-0.363764</td>\n",
       "      <td>-1.729695</td>\n",
       "      <td>-1.361653</td>\n",
       "      <td>-0.333247</td>\n",
       "      <td>-1.261648</td>\n",
       "      <td>-1.278404</td>\n",
       "      <td>-0.194342</td>\n",
       "      <td>0.127119</td>\n",
       "      <td>0.239934</td>\n",
       "      <td>-0.591152</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.090771</td>\n",
       "      <td>-1.626365</td>\n",
       "      <td>-1.190789</td>\n",
       "      <td>-0.851755</td>\n",
       "      <td>-0.871202</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44065</th>\n",
       "      <td>1.750195</td>\n",
       "      <td>-1.729695</td>\n",
       "      <td>-1.361653</td>\n",
       "      <td>-1.563035</td>\n",
       "      <td>-0.762843</td>\n",
       "      <td>-0.002432</td>\n",
       "      <td>1.298727</td>\n",
       "      <td>1.348476</td>\n",
       "      <td>9.462864</td>\n",
       "      <td>0.500179</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052672</td>\n",
       "      <td>-1.626365</td>\n",
       "      <td>-0.880976</td>\n",
       "      <td>-0.139049</td>\n",
       "      <td>-0.358082</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39538</th>\n",
       "      <td>0.904612</td>\n",
       "      <td>-1.162983</td>\n",
       "      <td>-0.963707</td>\n",
       "      <td>-0.333247</td>\n",
       "      <td>0.484171</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>-1.058751</td>\n",
       "      <td>-0.650109</td>\n",
       "      <td>-0.610407</td>\n",
       "      <td>-1.471258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.973102</td>\n",
       "      <td>-1.626365</td>\n",
       "      <td>-0.674434</td>\n",
       "      <td>-0.632461</td>\n",
       "      <td>-0.646712</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105427</th>\n",
       "      <td>0.904612</td>\n",
       "      <td>-0.596270</td>\n",
       "      <td>-0.565762</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>-0.762843</td>\n",
       "      <td>-0.512820</td>\n",
       "      <td>0.591484</td>\n",
       "      <td>0.349184</td>\n",
       "      <td>-0.610407</td>\n",
       "      <td>1.204263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134851</td>\n",
       "      <td>-1.071018</td>\n",
       "      <td>-1.190789</td>\n",
       "      <td>-0.742108</td>\n",
       "      <td>-0.326012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148669</th>\n",
       "      <td>-1.209348</td>\n",
       "      <td>1.670580</td>\n",
       "      <td>1.821910</td>\n",
       "      <td>1.343736</td>\n",
       "      <td>-0.014635</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>-0.194342</td>\n",
       "      <td>0.571249</td>\n",
       "      <td>-0.741229</td>\n",
       "      <td>-1.154420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693685</td>\n",
       "      <td>0.039675</td>\n",
       "      <td>-0.054807</td>\n",
       "      <td>0.189892</td>\n",
       "      <td>-0.486362</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n",
       "60700  -0.363764   -1.729695   -1.361653  -0.333247       -1.261648   \n",
       "44065   1.750195   -1.729695   -1.361653  -1.563035       -0.762843   \n",
       "39538   0.904612   -1.162983   -0.963707  -0.333247        0.484171   \n",
       "105427  0.904612   -0.596270   -0.565762   0.002149       -0.762843   \n",
       "148669 -1.209348    1.670580    1.821910   1.343736       -0.014635   \n",
       "\n",
       "        eyesight(right)  systolic  relaxation  fasting blood sugar  \\\n",
       "60700         -1.278404 -0.194342    0.127119             0.239934   \n",
       "44065         -0.002432  1.298727    1.348476             9.462864   \n",
       "39538          0.507957 -1.058751   -0.650109            -0.610407   \n",
       "105427        -0.512820  0.591484    0.349184            -0.610407   \n",
       "148669         0.507957 -0.194342    0.571249            -0.741229   \n",
       "\n",
       "        Cholesterol  ...  hemoglobin  serum creatinine       AST       ALT  \\\n",
       "60700     -0.591152  ...   -2.090771         -1.626365 -1.190789 -0.851755   \n",
       "44065      0.500179  ...    1.052672         -1.626365 -0.880976 -0.139049   \n",
       "39538     -1.471258  ...   -0.973102         -1.626365 -0.674434 -0.632461   \n",
       "105427     1.204263  ...   -0.134851         -1.071018 -1.190789 -0.742108   \n",
       "148669    -1.154420  ...   -0.693685          0.039675 -0.054807  0.189892   \n",
       "\n",
       "             Gtp  hearing(left)  hearing(right)  Urine protein  dental caries  \\\n",
       "60700  -0.871202              1               1              1              0   \n",
       "44065  -0.358082              1               1              1              0   \n",
       "39538  -0.646712              1               1              1              0   \n",
       "105427 -0.326012              1               1              1              0   \n",
       "148669 -0.486362              1               1              1              0   \n",
       "\n",
       "        smoking  \n",
       "60700         0  \n",
       "44065         0  \n",
       "39538         0  \n",
       "105427        0  \n",
       "148669        0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path2+\"\\\\data_cleaned_withoutPCA.csv\", index_col = 0)\n",
    "df = data.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb6577",
   "metadata": {},
   "source": [
    "#### Récupération d'un sample du dataframe pour effectuer les différents test de modélisation\n",
    "\n",
    "##### La colonne sera ensuite mute une fois les tests terminés pour utiliser l'ensemble du dataframe\n",
    "df = df.sample(10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706f1b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159256, 23)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7bca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df.drop(\"smoking\", axis = 1), df[\"smoking\"]\n",
    "X_train,X_test,y_train, y_test = train_test_split(X,y, random_state=42,\n",
    "                                                 test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f97302",
   "metadata": {},
   "source": [
    "# Plan : \n",
    "\n",
    "## 1. Création de fonction de modélisation et  Préparation des modèles\n",
    "\n",
    "## 2. Entrainement des modèles\n",
    "\n",
    "## 3. Résultats et premières selection de modèles\n",
    "\n",
    "## 4. Visualisation des autres metrics\n",
    "\n",
    "## 5. Amélioration des modèles par GridSearchCV\n",
    "## 6. Visualisation des performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657bad4",
   "metadata": {},
   "source": [
    "# 1. Création des fonctions de modélisation et préparation des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922bf975",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model = [DummyClassifier(),\n",
    "             LogisticRegression(),\n",
    "             KNeighborsClassifier(),\n",
    "             SGDClassifier(),\n",
    "             SVC(),\n",
    "             RandomForestClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e848fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Création d'une fonction d'entrainement pour un modèle donné\n",
    "\n",
    "def train_model(model):\n",
    "    \"\"\"le modèle sera entrainé par validation score sur 5 split\n",
    "    et affichage du score moyen.\n",
    "    la fonction renvoi les prédiction du modèle entrainé et le temps d'entrainement\"\"\"\n",
    "    scores = (cross_val_score(estimator=model, X=X_train,y=y_train, cv=5)).mean()\n",
    "    print(str(model))\n",
    "    print(\"Score moyen validation croisée :\", scores.round(2))\n",
    "    \n",
    "    # Mesurer le temps de début\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #Entrainement du modele\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    # Mesurer le temps de fin\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculer la durée totale\n",
    "    training_time = round(end_time - start_time,2)\n",
    "    #Convertir la duree en minute :\n",
    "    training_time_min = round(training_time/60,2)\n",
    "\n",
    "    yp = model.predict(X_test.values) #rajout ici '.values' pour que ca fonctionne\n",
    "    return yp,training_time_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13afae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Création d'une fonction qui renvoi l'ensemble des metrics :\n",
    "\n",
    "def metric(prediction, model_name, exe_time):\n",
    "    \"\"\"Fonction qui renvoi un dataframe contenant les valeurs des metrics\n",
    "    principales : f1score, accuracy, recall, precision score et le temps d'execution\n",
    "    à partir de la liste des prédictions d'un modèle\"\"\"\n",
    "    \n",
    "    f1 = metrics.f1_score(y_true = y_test, y_pred = prediction)\n",
    "    accuracy = metrics.accuracy_score(y_true = y_test, y_pred = prediction)\n",
    "    recal = metrics.recall_score(y_true = y_test, y_pred = prediction)\n",
    "    precision = metrics.precision_score(y_true = y_test, y_pred = prediction)\n",
    "    \n",
    "    all_metric = [f1,accuracy,recal,precision, exe_time]\n",
    "    \n",
    "    index_metric = [\"F1\",\"accuracy\",\"recall\",\"precision\",\"Duree_entrainement\"]\n",
    "    \n",
    "    series = pd.Series(all_metric, name=str(model_name), index=index_metric)\n",
    "    return pd.DataFrame(series)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a15ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fonction pour créer une matrice de confusion : \n",
    "\n",
    "def matrice_confusion(prediction):\n",
    "    cf = metrics.confusion_matrix(y_true=y_test, y_pred=prediction)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    ax = sns.heatmap(cf, annot = True, linewidths=0.8, linecolor=\"black\", fmt = \".0f\",cbar=False, cmap = \"Blues\")\n",
    "    ax.set_xlabel('Prédictions')\n",
    "    ax.set_ylabel('Valeurs réelles')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f058133",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fonction pour obtenir la learning curve d'un modèle : \n",
    "def learning_curv(model):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model,\n",
    "                                                                X_train, y_train, cv=5)\n",
    "    \n",
    "# Calcul des scores moyens pour l'apprentissage et la validation\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# Tracer les courbes d'apprentissage\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.plot(train_sizes, train_scores_mean, label='Score d\\'entraînement moyen')\n",
    "    plt.plot(train_sizes, test_scores_mean, label='Score de validation moyen')\n",
    "    plt.xlabel('Taille de l\\'ensemble d\\'entraînement')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Courbes d\\'apprentissage')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efca9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fonction pour obtenir la courbe ROC : \n",
    "\n",
    "def ROC(prediction):\n",
    "    FP_rate, TP_rate, thresholds = metrics.roc_curve(y_test,prediction)\n",
    "    roc_auc = metrics.auc(FP_rate,TP_rate)\n",
    "    print(\"ROC_AUC =\", roc_auc.round(2))\n",
    "    \n",
    "    \n",
    "    ### Création de la courbe AUC ROC :\n",
    "    plt.figure(figsize=(6,6))\n",
    "    \n",
    "    #Courbe prédictive :\n",
    "    sns.lineplot(x = FP_rate, y = TP_rate, color = \"orange\", label = f\"AUC = {roc_auc:,.2f}%\")\n",
    "    \n",
    "    #Courbe random :\n",
    "    sns.lineplot(x=[0,1],y=[0,1], linestyle = \"--\", c = \"r\", label= \"Random Classifier\")\n",
    "\n",
    "    plt.ylabel(\"True Positive rate\")\n",
    "    plt.xlabel(\"False Positive rate\")\n",
    "    plt.title(\"ROC\")\n",
    "    plt.legend(loc = \"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3976df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fonction permettant d'améliorer un modèle grâce au GridSearchCV :\n",
    "\n",
    "def Grid(model, param):\n",
    "    \"\"\"Le modèle sera entrainé sur 5 splits\n",
    "    et renverra les prédictions du meilleur modèles ainsi que son temps d'entrainement\"\"\"\n",
    "    \n",
    " # Mesurer le temps de début\n",
    "    start_time = time.time()\n",
    "        \n",
    "    #Entrainement du grid sur les paramètres\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    # Mesurer le temps de fin\n",
    "    end_time = time.time()\n",
    "    \n",
    "    #Recuperation des meilleurs hyper parametres :\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    #Recuperation des predictions\n",
    "    yp = best_model.predict(X_test)\n",
    "    \n",
    "    #Calcul temps d'execution:\n",
    "    training_time = round(end_time- start_time  , 3)\n",
    "    #On converti en minutes :\n",
    "    training_time_min = round(training_time/60,2)\n",
    "    \n",
    "    return yp, training_time_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a9ea07",
   "metadata": {},
   "source": [
    "## 2. Entrainement des différents modèles et récupération des metrics :\n",
    "- Nous allons créer une boucle qui va parcourir notre liste des modèles utilisés et qui fera :\n",
    "    - Entrainement des modèles et récupèrera les prédictions et les temps d'execution\n",
    "    - Enregistrement du modèle sur pickle\n",
    "    - Ajout des metrics dans le dictionnaire dict_metric\n",
    "    - ajout des prédiction dans le dictionnaire dict_prediction\n",
    "    -  enregistrement final dans un dataframe contenant les différentes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e58e9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r'D://Etude_Data_science//Kaggle_competition//02_Binary_Prediction_of_Smoker_Status_using_Bio-Signals/Modeles/\\\\withoutPCA\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1113debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_metric = {}\n",
    "for current_model in all_model:\n",
    "    prediction, temps_exe = train_model(current_model)\n",
    "    dict_metric[str(current_model)] = metric(prediction=prediction, model_name=str(current_model), exe_time=temps_exe)\n",
    "df_metrics = pd.concat(dict_metric.values(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8959005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionnaire qui contiendra les différentes metrics de chaque modèle\n",
    "dict_metric = {}\n",
    "\n",
    "#dictionnaire contenant les valeurs prédictives pour chaque modèles\n",
    "dict_prediction = {}\n",
    "\n",
    "for current_model in all_model:\n",
    "    #Recuperation des prédictions et du temps d'execution de chaque modèles\n",
    "    prediction, temps_exe = train_model(current_model)\n",
    "    \n",
    "    \n",
    "    # Récupération du nom du modèle et du chemin d'enregistrement\n",
    "    model_name = str(current_model)\n",
    "    model_filename = os.path.join(save_path, f\"{model_name}.pkl\")\n",
    "    \n",
    "    #Enregistrement des modèles préentrainé :\n",
    "    with open(model_filename, 'wb') as model_file:\n",
    "        pickle.dump(current_model, model_file)\n",
    "    \n",
    "    #Enregistrement des prédiction dans le dictionnaire :\n",
    "    dict_prediction[model_name] = prediction\n",
    "    \n",
    "    # Enregistrement des métriques au dictionnaire\n",
    "    dict_metric[model_name] = metric(prediction=prediction, model_name=model_name, exe_time=temps_exe)\n",
    "\n",
    "\n",
    "    \n",
    "#Pour les Dataframe :\n",
    "    \n",
    "# Concaténation des métriques en un DataFrame\n",
    "df_metrics = pd.concat(dict_metric.values(), axis=1)\n",
    "#intervertissons les colonnes et les indexs :\n",
    "df_metrics = df_metrics.T\n",
    "# Enregistrement du DataFrame des métriques\n",
    "df_metrics.to_csv(\"df_metrics.csv\")\n",
    "\n",
    "\n",
    "#Enregistrement des prédictions dans un dataframe :\n",
    "df_prediction = pd.DataFrame(dict_prediction)\n",
    "# Enregistrement du DataFrame des prédictions\n",
    "df_prediction.to_csv(\"df_prediction.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57bd46",
   "metadata": {},
   "source": [
    "### 3. Résultats et premières selection de modèles\n",
    "- Nous allons déja effectuer un premier filtre de modèles en supprimant ceux qui mettent beaucoup trop de temps à s'entrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29673a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = df_metrics.T\n",
    "df_metrics.sort_values(by = \"F1\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95939a8b",
   "metadata": {},
   "source": [
    "### Observation :\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c41d79f",
   "metadata": {},
   "source": [
    "### Conclusion :\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba67ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = df_prediction.drop([\"listemodele_\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed086fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6a0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cfc9c76",
   "metadata": {},
   "source": [
    "## 4. Visualisation des autres metrics : \n",
    "\n",
    "### matrice de confusion : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36245d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_prediction:\n",
    "    print(i)\n",
    "    matrice_confusion(df_prediction[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d9c4ca",
   "metadata": {},
   "source": [
    "### ROC :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c99cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_prediction:\n",
    "    print(i)\n",
    "    ROC(df_prediction[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639eca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6020f385",
   "metadata": {},
   "source": [
    "### Observation \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed039a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06698d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62419dc5",
   "metadata": {},
   "source": [
    "## 5. Amélioration des modèles par GridSearchCV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
