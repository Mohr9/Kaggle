{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Academic Success\n",
    "## 2. Modélisation\n",
    "- Ce notebook fait suite au notebook **01_EDA_Academic_Success** https://www.kaggle.com/code/mohamedabder/01-eda-academic-success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:03.577051Z",
     "iopub.status.busy": "2024-06-18T18:20:03.576618Z",
     "iopub.status.idle": "2024-06-18T18:20:07.373072Z",
     "shell.execute_reply": "2024-06-18T18:20:07.371575Z",
     "shell.execute_reply.started": "2024-06-18T18:20:03.577011Z"
    }
   },
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import time \n",
    "\n",
    "\n",
    "#modeles :\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import pickle \n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données\n",
    "- Séparation train test set\n",
    "- Encodage de la target et enregistrement de l'encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:07.377337Z",
     "iopub.status.busy": "2024-06-18T18:20:07.376231Z",
     "iopub.status.idle": "2024-06-18T18:20:07.383467Z",
     "shell.execute_reply": "2024-06-18T18:20:07.381927Z",
     "shell.execute_reply.started": "2024-06-18T18:20:07.377293Z"
    }
   },
   "outputs": [],
   "source": [
    "path1 = 'D:\\\\etude_data_science\\\\kaggle_competition\\\\07_academic_success\\\\dataset\\\\'\n",
    "os.listdir(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_path = os.path.join(path1,os.listdir(path1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(df_preprocessed_path, index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_scaler = os.path.join(os.getcwd(),\"scaler.pkl\")\n",
    "path_labelencoder = os.path.join(os.getcwd(),\"target_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:07.386509Z",
     "iopub.status.busy": "2024-06-18T18:20:07.386010Z",
     "iopub.status.idle": "2024-06-18T18:20:07.417979Z",
     "shell.execute_reply": "2024-06-18T18:20:07.416474Z",
     "shell.execute_reply.started": "2024-06-18T18:20:07.386467Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ouvrir le fichier en mode binaire de lecture\n",
    "with open(path_scaler, 'rb') as file:\n",
    "    # Lire et désérialiser l'objet\n",
    "    scaler = pickle.load(file)\n",
    "print(f\"Données chargées depuis {colored(path_scaler,'blue')} : {colored(scaler,'green',attrs=['bold'])}\")\n",
    "\n",
    "# Ouvrir le fichier en mode binaire de lecture\n",
    "with open(path_labelencoder, 'rb') as file:\n",
    "    # Lire et désérialiser l'objet\n",
    "    labelencoder = pickle.load(file)\n",
    "print(f\"Données chargées depuis {colored(path_labelencoder,'blue')} : {colored(labelencoder,'green',attrs=['bold'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:07.421553Z",
     "iopub.status.busy": "2024-06-18T18:20:07.421200Z",
     "iopub.status.idle": "2024-06-18T18:20:08.084894Z",
     "shell.execute_reply": "2024-06-18T18:20:08.083473Z",
     "shell.execute_reply.started": "2024-06-18T18:20:07.421522Z"
    }
   },
   "outputs": [],
   "source": [
    "#Chargement du dataframe preprocessed : \n",
    "data_cleaned = pd.read_csv(path_train, index_col = 0)\n",
    "df = data_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:08.087152Z",
     "iopub.status.busy": "2024-06-18T18:20:08.086640Z",
     "iopub.status.idle": "2024-06-18T18:20:08.105941Z",
     "shell.execute_reply": "2024-06-18T18:20:08.104481Z",
     "shell.execute_reply.started": "2024-06-18T18:20:08.087109Z"
    }
   },
   "outputs": [],
   "source": [
    "#Récupération des types de variables\n",
    "var_cont = list(df.select_dtypes(\"float\"))\n",
    "var_dis = list(df.select_dtypes(\"int\"))\n",
    "var_qual = list(df.select_dtypes('object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:08.108753Z",
     "iopub.status.busy": "2024-06-18T18:20:08.108290Z",
     "iopub.status.idle": "2024-06-18T18:20:08.118498Z",
     "shell.execute_reply": "2024-06-18T18:20:08.116951Z",
     "shell.execute_reply.started": "2024-06-18T18:20:08.108711Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Séparation de l'ID et préparation du train et test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:08.121078Z",
     "iopub.status.busy": "2024-06-18T18:20:08.120592Z",
     "iopub.status.idle": "2024-06-18T18:20:08.137651Z",
     "shell.execute_reply": "2024-06-18T18:20:08.136210Z",
     "shell.execute_reply.started": "2024-06-18T18:20:08.121038Z"
    }
   },
   "outputs": [],
   "source": [
    "identifiant = df[\"id\"]\n",
    "df.drop(identifiant.name, axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df.drop(\"Target\", axis =1), df[\"Target\"]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, stratify =y,  #pour rappel, dans la partie EDA nous avions remarqué que les classes n'étaient pas équilibrées\n",
    "                                                 test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:08.185233Z",
     "iopub.status.busy": "2024-06-18T18:20:08.184765Z",
     "iopub.status.idle": "2024-06-18T18:20:08.191716Z",
     "shell.execute_reply": "2024-06-18T18:20:08.190545Z",
     "shell.execute_reply.started": "2024-06-18T18:20:08.185200Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Dimensions après split des données :\\n\")\n",
    "print(f\"X train :{X_train.shape}\")\n",
    "print(f\"y train :{y_train.shape}\")\n",
    "print()\n",
    "print(f\"X test :{X_test.shape}\")\n",
    "print(f\"y test :{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage de la target et enregistrement de l'encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:08.196269Z",
     "iopub.status.busy": "2024-06-18T18:20:08.195854Z",
     "iopub.status.idle": "2024-06-18T18:20:08.215752Z",
     "shell.execute_reply": "2024-06-18T18:20:08.214476Z",
     "shell.execute_reply.started": "2024-06-18T18:20:08.196236Z"
    }
   },
   "outputs": [],
   "source": [
    "#Entrainement de l'encoder\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:08.217688Z",
     "iopub.status.busy": "2024-06-18T18:20:08.217258Z",
     "iopub.status.idle": "2024-06-18T18:20:08.227129Z",
     "shell.execute_reply": "2024-06-18T18:20:08.225969Z",
     "shell.execute_reply.started": "2024-06-18T18:20:08.217651Z"
    }
   },
   "outputs": [],
   "source": [
    "#Enregistrement de l'encoder pré-entrainé\n",
    "with open('target_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(labelencoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:08.229357Z",
     "iopub.status.busy": "2024-06-18T18:20:08.228928Z",
     "iopub.status.idle": "2024-06-18T18:20:08.264144Z",
     "shell.execute_reply": "2024-06-18T18:20:08.262587Z",
     "shell.execute_reply.started": "2024-06-18T18:20:08.229317Z"
    }
   },
   "outputs": [],
   "source": [
    "#Encodage de la target :\n",
    "y_train,y_test = labelencoder.transform(y_train),labelencoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Maintenant que les données ont été préparées, nous pouvons désormais passer aux différentes étapes de la modélisation.\n",
    "\n",
    "# Plan : \n",
    "#### 1. Création des fonctions de modélisation \n",
    "\n",
    "#### 2. Entrainement et enregistrement des modèles\n",
    "\n",
    "#### 3. Résultats et premières selection de modèles\n",
    "\n",
    "#### 4. Visualisation des autres metrics\n",
    "\n",
    "#### 5. Amélioration des modèles par GridSearchCV\n",
    "\n",
    "#### 6. Visualisation des performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. Création des fonctions de modélisation\n",
    "### Fonction pour l'entrainement et la récupération des metrics des modèles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:08.266353Z",
     "iopub.status.busy": "2024-06-18T18:20:08.265909Z",
     "iopub.status.idle": "2024-06-18T18:20:08.286003Z",
     "shell.execute_reply": "2024-06-18T18:20:08.284547Z",
     "shell.execute_reply.started": "2024-06-18T18:20:08.266310Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    \"\"\"Fonction qui entraine un modèle et affiche le score obtenu sur 5 splits après\n",
    "    cross validation et le score moyen. \n",
    "    Renvoi un tuple de trois éléments :\n",
    "    (predictions, temps d'execution, le modèle entrainé)\"\"\"\n",
    "    \n",
    "    scores = cross_val_score(estimator=model, X=X_train.values, y=y_train)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    OneVsRestClassifier(model.fit(X_train,y_train)) #transforme un problème de classification\n",
    "    #multi-classes en plusieurs problèmes de classification binaire.\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # durée totale de l'entrainement \n",
    "    training_time = round(end_time - start_time,2)\n",
    "    \n",
    "    # Durée en minute :\n",
    "    training_time_min = round(training_time/60,2)\n",
    "\n",
    "    yp = model.predict(X_test.values)\n",
    "    \n",
    "    print(colored(type(model).__name__,\"light_green\",attrs=[\"bold\"]))\n",
    "    print(\"Scores sur 5 splits : \", [i.round(3) for i in scores])\n",
    "    print(\"Score moyen :\", scores.mean().round(3))\n",
    "\n",
    "    return (yp, training_time_min, model)\n",
    "\n",
    "def metric(prediction, model_name):\n",
    "    \"\"\"Fonction qui renvoie un objet pandas Series contenant les valeurs des metrics\n",
    "    principales : f1 score, accuracy, recall, precision score à partir de la liste des prédictions d'un modèle\"\"\"\n",
    "    \n",
    "    f1 = metrics.f1_score(y_true = y_test, y_pred = prediction, average='weighted')\n",
    "    accuracy = metrics.accuracy_score(y_true = y_test, y_pred = prediction)\n",
    "    recal = metrics.recall_score(y_true = y_test, y_pred = prediction, average='weighted')\n",
    "    precision = metrics.precision_score(y_true = y_test, y_pred = prediction, average='weighted')\n",
    "    \n",
    "    all_metric = [f1,accuracy,recal,precision]\n",
    "    \n",
    "    index_metric = [\"F1-score\",\"Accuracy\",\"Recall\",\"Precision\"]\n",
    "    \n",
    "    series = pd.Series(all_metric, name=str(model_name), index=index_metric)\n",
    "    return pd.DataFrame(series)\n",
    "\n",
    "def trainig_series(list_models):\n",
    "    \"\"\"Fonction qui entraine en série plusieurs modèle à la fois\n",
    "    Renvoie un tuple contenant 4 éléments :\n",
    "    DataFrame contenant toutes les métrics\n",
    "    DataFrame contenant toutes les prédictions de modèles\n",
    "    Dictionnaire contenant tout les modèles préentrainés\n",
    "    Dictionnaire contenant le temps d'entrainement de chaque modèle\n",
    "    \"\"\"\n",
    "    #Dictionnaire qui contiendra les différentes metrics de chaque modèle\n",
    "    dict_metric = {}\n",
    "    #dictionnaire contenant les valeurs prédictives pour chaque modèles\n",
    "    dict_prediction = {}\n",
    "    #dictionnaire contenant les modele entrainé\n",
    "    dict_model_trained = {}\n",
    "    #dictionnaire contenant le temps d'exécution \n",
    "    dict_time ={}\n",
    "        \n",
    "    \n",
    "    for current_model in list_models:\n",
    "        #Recuperation des prédictions et du temps d'execution de chaque modèles\n",
    "        prediction, temps_exe, model_trained = train(current_model)\n",
    "\n",
    "        # Récupération du nom du modèle et du chemin d'enregistrement\n",
    "        model_name = type(current_model).__name__\n",
    "\n",
    "        # Enregitrement des modèles après entrainement : \n",
    "        dict_model_trained[model_name] = model_trained\n",
    "\n",
    "        #Enregistrement des prédiction dans le dictionnaire :\n",
    "        dict_prediction[model_name] = prediction\n",
    "\n",
    "        # Enregistrement des métriques au dictionnaire\n",
    "        dict_metric[model_name] = metric(prediction=prediction, model_name=model_name)\n",
    "        \n",
    "        #Enregistrement du tps d'execution\n",
    "        dict_time[model_name] = temps_exe  \n",
    "        \n",
    "    #Pour les Dataframe :    \n",
    "    # Concaténation des métriques en un DataFrame et inversion des colonnes et index :\n",
    "    df_metrics = pd.concat(dict_metric.values(), axis=1).T \n",
    "    #Enregistrement des prédictions dans un dataframe :\n",
    "    df_prediction = pd.DataFrame(dict_prediction)\n",
    "    \n",
    "    return (df_metrics,df_prediction,dict_model_trained, dict_time)\n",
    "\n",
    "def enregistrement_model(pretrained_models):\n",
    "    \"\"\"Prend en entrée un dictionnaire sous forme {nom_modèle : modèle préentrainé}\"\"\"\n",
    "    for i in pretrained_models:\n",
    "        model_name = i\n",
    "        current_model = pretrained_models[model_name]\n",
    "        model_filename = os.path.join(f\"{model_name}.pkl\")\n",
    "        #Enregistrement des modèles préentrainé :\n",
    "        with open(model_filename, 'wb') as model_file:\n",
    "            pickle.dump(current_model, model_file)\n",
    "        print(f'{colored(model_name,\"blue\")} enregistré sous {colored(model_filename,\"green\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction pour la visualisation des résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:08.287944Z",
     "iopub.status.busy": "2024-06-18T18:20:08.287425Z",
     "iopub.status.idle": "2024-06-18T18:20:08.306099Z",
     "shell.execute_reply": "2024-06-18T18:20:08.305030Z",
     "shell.execute_reply.started": "2024-06-18T18:20:08.287900Z"
    }
   },
   "outputs": [],
   "source": [
    " #visualisation du temp d'entrainement\n",
    "def graph_time(dictionnary_time):\n",
    "    \"\"\"Fonction qui récupère un dictionnaire contenant les informations sur la durée d'entrainement des modèles et renvoie un barplot\"\"\"\n",
    "    df_time = pd.DataFrame.from_dict(dictionnary_time, orient = \"index\", columns=[\"Duree d'entrainement\"])\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.grid()\n",
    "    ax = sns.barplot(x = df_time.index, y = df_time.columns[0], data = df_time)\n",
    "    ax.set_xticklabels(labels = df_time.index, rotation = 45)\n",
    "    plt.xlabel(\"Modèles\")\n",
    "    plt.title(\"Durée d'entrainement des différents modèles (en minutes)\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "#Visualisation des metrics avec un barplot\n",
    "def metric_plot(df_metric):\n",
    "    mesure_reset = df_metric.reset_index()\n",
    "    # Ensuite, ON utilise melt avec le nouvel index comme id_vars\n",
    "    metric_df_melt = mesure_reset.melt(id_vars=\"index\", var_name=\"Model\", value_name=\"Score\")\n",
    "\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.grid()\n",
    "    sns.barplot(data=metric_df_melt, x=\"index\", y=\"Score\", hue=\"Model\")\n",
    "    plt.legend(bbox_to_anchor=(1,1))\n",
    "    plt.title('Comparaison des scores des modèles')\n",
    "    plt.show()\n",
    "    \n",
    "#visualisation de la matrice de confusion\n",
    "def matrice(prediction):\n",
    "    cf = metrics.confusion_matrix(y_true=y_test, y_pred=prediction)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    ax = sns.heatmap(cf, annot = True, linewidths=0.8, linecolor=\"black\", fmt = \".0f\",cbar=False, cmap = \"Blues\")\n",
    "    ax.set_xlabel('Prédictions')\n",
    "    ax.set_ylabel('Valeurs réelles')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "#visualisation de la courbe ROC   \n",
    "def ROC(model):\n",
    "    \"\"\"Fonction pour obtenir la courbe ROC pour la classification multiclasse\"\"\"\n",
    "    n_classes = len(np.unique(y_test))\n",
    "    # Binarisez les étiquettes (labels) pour pouvoir les utiliser dans roc_curve\n",
    "    y_test_binarized = label_binarize(y_test, classes=model.classes_)\n",
    "    predicted_probabilities = model.predict_proba(X_test.values)\n",
    "\n",
    "    # Initialisez la figure pour le tracé\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Calculez la courbe ROC pour chaque classe\n",
    "    for i in range(len(model.classes_)):\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_test_binarized[:, i], predicted_probabilities[:, i])\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'Classe {model.classes_[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    # Tracer la ligne en pointillés représentant la performance aléatoire\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='r', label='Aléatoire')\n",
    "\n",
    "    # Ajoutez des légendes, un titre et des étiquettes d'axe\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.xlabel('Taux de faux positifs (FPR)')\n",
    "    plt.ylabel('Taux de vrais positifs (TPR)')\n",
    "    plt.title('Courbe ROC pour un problème de classification multiclasse')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrainement et enregistrement des modèles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:08.307940Z",
     "iopub.status.busy": "2024-06-18T18:20:08.307474Z",
     "iopub.status.idle": "2024-06-18T18:20:08.323238Z",
     "shell.execute_reply": "2024-06-18T18:20:08.321692Z",
     "shell.execute_reply.started": "2024-06-18T18:20:08.307901Z"
    }
   },
   "outputs": [],
   "source": [
    "##### Liste des modèles utilisés :\n",
    "all_model = [\n",
    "    DummyClassifier(strategy=\"most_frequent\"),\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(),\n",
    "    SGDClassifier(loss=\"modified_huber\"), \n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    XGBClassifier()\n",
    "            ]\n",
    "\n",
    "#Remarque : loss = \"modified_huber\" SGDC,cela permet d'utiliser le \"predict_proba(X_test.values)\"\n",
    "# c'est indispensable à notre fonction ROC (car on utilise predict_proba et label_binarizer)\n",
    "#sinon cela ne fonctionne pas car la courbe ROC n'est pas adapté aux problèmes non binaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:20:08.326681Z",
     "iopub.status.busy": "2024-06-18T18:20:08.326195Z",
     "iopub.status.idle": "2024-06-18T18:23:28.966555Z",
     "shell.execute_reply": "2024-06-18T18:23:28.965071Z",
     "shell.execute_reply.started": "2024-06-18T18:20:08.326638Z"
    }
   },
   "outputs": [],
   "source": [
    "#Entrainement en série :\n",
    "mesure, prediction,model_entraine, exe_time = trainig_series(all_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:23:28.968290Z",
     "iopub.status.busy": "2024-06-18T18:23:28.967915Z",
     "iopub.status.idle": "2024-06-18T18:23:29.271338Z",
     "shell.execute_reply": "2024-06-18T18:23:29.270186Z",
     "shell.execute_reply.started": "2024-06-18T18:23:28.968258Z"
    }
   },
   "outputs": [],
   "source": [
    "#Sauvegarde des modèles préentrainé :\n",
    "enregistrement_model(model_entraine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des premiers résultats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:23:29.272981Z",
     "iopub.status.busy": "2024-06-18T18:23:29.272600Z",
     "iopub.status.idle": "2024-06-18T18:23:29.787707Z",
     "shell.execute_reply": "2024-06-18T18:23:29.786479Z",
     "shell.execute_reply.started": "2024-06-18T18:23:29.272950Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_plot(mesure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:23:29.789399Z",
     "iopub.status.busy": "2024-06-18T18:23:29.789068Z",
     "iopub.status.idle": "2024-06-18T18:23:30.124547Z",
     "shell.execute_reply": "2024-06-18T18:23:30.123263Z",
     "shell.execute_reply.started": "2024-06-18T18:23:29.789370Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_time(exe_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:23:30.126528Z",
     "iopub.status.busy": "2024-06-18T18:23:30.126170Z",
     "iopub.status.idle": "2024-06-18T18:23:30.134624Z",
     "shell.execute_reply": "2024-06-18T18:23:30.133205Z",
     "shell.execute_reply.started": "2024-06-18T18:23:30.126498Z"
    }
   },
   "outputs": [],
   "source": [
    "def matrice(pred, nrow, ncol):\n",
    "    plt.figure(figsize=(14, 14))  \n",
    "    for i, col in enumerate(pred, 1):\n",
    "        cf = metrics.confusion_matrix(y_true=y_test, y_pred=pred[col])\n",
    "        ax = plt.subplot(nrow, ncol, i)\n",
    "        sns.heatmap(cf, annot=True, ax=ax,linewidths=0.8, linecolor=\"black\",fmt=\".0f\", cbar=False, cmap=\"Blues\")\n",
    "        ax.set_xlabel('Prédictions')\n",
    "        ax.set_ylabel('Valeurs réelles')\n",
    "        ax.set_title(f\"{col}\")\n",
    "    plt.tight_layout()  # Pour éviter les chevauchements\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:23:30.136838Z",
     "iopub.status.busy": "2024-06-18T18:23:30.136355Z",
     "iopub.status.idle": "2024-06-18T18:23:30.149488Z",
     "shell.execute_reply": "2024-06-18T18:23:30.148067Z",
     "shell.execute_reply.started": "2024-06-18T18:23:30.136795Z"
    }
   },
   "outputs": [],
   "source": [
    "def ROC(model_list, nrow,ncol):\n",
    "    \"\"\"Fonction pour obtenir la courbe ROC pour la classification multiclasse\"\"\"\n",
    "    n_classes = len(np.unique(y_test))\n",
    "    plt.figure(figsize=(15, 10))  \n",
    "\n",
    "    # Binarisation de la target pouvoir l'utiliser dans roc_curve\n",
    "    y_test_binarized = label_binarize(y_test, classes=np.unique(y_test))\n",
    "    \n",
    "    # Boucle sur chaque modèle et on trace la courbe ROC dans un sous-graphique\n",
    "    for i, model in enumerate(model_list, 1):\n",
    "        plt.subplot(nrow, ncol, i)  \n",
    "        predicted_probabilities = model_list[model].predict_proba(X_test.values)\n",
    "        \n",
    "        # On calcul et on trace la courbe ROC pour chaque classe\n",
    "        for j in range(n_classes):\n",
    "            fpr, tpr, _ = metrics.roc_curve(y_test_binarized[:, j], predicted_probabilities[:, j])\n",
    "            roc_auc = metrics.auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f'Classe {j} (AUC = {roc_auc:.2f})')\n",
    "        \n",
    "        # On trace la ligne en pointillés représentant la performance aléatoire\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', color='r', label='Aléatoire')\n",
    "        \n",
    "        #legende :\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.xlabel('Taux de faux positifs (FPR)')\n",
    "        plt.ylabel('Taux de vrais positifs (TPR)')\n",
    "        plt.title(f'Courbe ROC - Modèle {model}')\n",
    "        plt.grid()\n",
    "    \n",
    "    plt.tight_layout()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:23:30.151701Z",
     "iopub.status.busy": "2024-06-18T18:23:30.151319Z",
     "iopub.status.idle": "2024-06-18T18:23:35.296923Z",
     "shell.execute_reply": "2024-06-18T18:23:35.295601Z",
     "shell.execute_reply.started": "2024-06-18T18:23:30.151666Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utilison la fonction ROC avec notre liste de modèles préentraînés\n",
    "ROC(model_entraine,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection du modèle \n",
    "- Au vu des performance, Randomforestclassifier et XGBClassifier offrent les meilleur résultats de base, donc nous allons en conserver un des deux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:23:35.298798Z",
     "iopub.status.busy": "2024-06-18T18:23:35.298431Z",
     "iopub.status.idle": "2024-06-18T18:23:35.303449Z",
     "shell.execute_reply": "2024-06-18T18:23:35.302302Z",
     "shell.execute_reply.started": "2024-06-18T18:23:35.298764Z"
    }
   },
   "outputs": [],
   "source": [
    "#Recuperation du XGBC :\n",
    "final_model = model_entraine['XGBClassifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction sur de nouvelles données :\n",
    "- Nous allons utiliser notre modèle sur les données test qui nous ont été fournies\n",
    "- Pour cela, nous allons créé une fonction permettant de prétraiter nos données directement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:23:35.305204Z",
     "iopub.status.busy": "2024-06-18T18:23:35.304810Z",
     "iopub.status.idle": "2024-06-18T18:23:35.535290Z",
     "shell.execute_reply": "2024-06-18T18:23:35.534228Z",
     "shell.execute_reply.started": "2024-06-18T18:23:35.305167Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(path_test)\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:23:35.537118Z",
     "iopub.status.busy": "2024-06-18T18:23:35.536722Z",
     "iopub.status.idle": "2024-06-18T18:23:35.545082Z",
     "shell.execute_reply": "2024-06-18T18:23:35.544010Z",
     "shell.execute_reply.started": "2024-06-18T18:23:35.537084Z"
    }
   },
   "outputs": [],
   "source": [
    "def new_prediction(model, data):\n",
    "    #Récupération des mêmes features que celles utilisés pour l'entrainement des modèles\n",
    "    columns = model.feature_names_in_\n",
    "    #Récupération de l'id du jeu de données\n",
    "    id_data = data[\"id\"]\n",
    "    #Préparation du dataframe à tester :\n",
    "    X = data[columns]\n",
    "    #Standardisation des données : \n",
    "    X[var_cont] = scaler.transform(X[var_cont])\n",
    "    \n",
    "    #Récupération des prédictions\n",
    "    numeric_prediction = model.predict(X)\n",
    "    \n",
    "    #Conversion des prédiction en données d'origine (textuelles et non numérique)\n",
    "    original_prediction = labelencoder.inverse_transform(numeric_prediction)\n",
    "    \n",
    "    #Transformation des prédictions en dataframe avec l'id en index\n",
    "    prediction_df = pd.DataFrame(original_prediction, columns = [\"Target\"], index = id_data)\n",
    "    return prediction_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:23:35.546749Z",
     "iopub.status.busy": "2024-06-18T18:23:35.546424Z",
     "iopub.status.idle": "2024-06-18T18:23:35.746058Z",
     "shell.execute_reply": "2024-06-18T18:23:35.745142Z",
     "shell.execute_reply.started": "2024-06-18T18:23:35.546721Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_data = new_prediction(final_model, df_test)\n",
    "submission_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:23:35.747911Z",
     "iopub.status.busy": "2024-06-18T18:23:35.747318Z",
     "iopub.status.idle": "2024-06-18T18:23:35.806166Z",
     "shell.execute_reply": "2024-06-18T18:23:35.804956Z",
     "shell.execute_reply.started": "2024-06-18T18:23:35.747855Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_data.to_csv(\"XGBClassifer_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Après soumission du modèle : Résultat 0.76239"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amélioration par GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:23:35.812999Z",
     "iopub.status.busy": "2024-06-18T18:23:35.812562Z",
     "iopub.status.idle": "2024-06-18T18:23:35.821297Z",
     "shell.execute_reply": "2024-06-18T18:23:35.819798Z",
     "shell.execute_reply.started": "2024-06-18T18:23:35.812964Z"
    }
   },
   "outputs": [],
   "source": [
    "def Grid(model, param):\n",
    "    \"\"\"Le modèle sera entrainé sur 5 splits\n",
    "    et renverra les prédictions du meilleur modèles ainsi que son temps d'entrainement\"\"\"\n",
    "    \n",
    " # Mesurer le temps de début\n",
    "    start_time = time.time()\n",
    "        \n",
    "    #Entrainement du grid sur les paramètres\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param, cv=5,verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "    grid.fit(X_train, y_train)\n",
    "    # Mesurer le temps de fin\n",
    "    end_time = time.time()\n",
    "    \n",
    "    #Recuperation des meilleurs hyper parametres :\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    # Convertir X_test en un format compatible si nécessaire\n",
    "    X_test_transformed = X_test.values  \n",
    "\n",
    "    \n",
    "    #Recuperation des predictions\n",
    "    yp = best_model.predict(X_test_transformed)\n",
    "    \n",
    "    #Calcul temps d'execution:\n",
    "    training_time = round(end_time- start_time  , 3)\n",
    "    #On converti en minutes :\n",
    "    training_time_min = round(training_time/60,2)\n",
    "    # Récupération du nom du modèle et du chemin d'enregistrement\n",
    "#     model_name = type(current_model).__name__\n",
    "#     dict_time = {model_name:training_time_min}\n",
    "    \n",
    "    return yp, training_time_min, best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:23:35.823417Z",
     "iopub.status.busy": "2024-06-18T18:23:35.823022Z",
     "iopub.status.idle": "2024-06-18T18:23:35.838249Z",
     "shell.execute_reply": "2024-06-18T18:23:35.836938Z",
     "shell.execute_reply.started": "2024-06-18T18:23:35.823386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Définition des paramètres de la grille\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Nombre d'arbres dans le modèle\n",
    "     'max_depth': [3, 4, 5],  # Profondeur maximale de chaque arbre\n",
    "     'learning_rate': [0.05, 0.1, 0.2],  # Taux d'apprentissage\n",
    "     'min_child_weight': [1, 3, 5],  # Poids minimum des enfants (minimum sum of instance weight(hessian) needed in a child)\n",
    "     'gamma': [0, 0.1, 0.2],  # Réduction de la perte minimale requise pour effectuer une partition sur une feuille\n",
    "     'colsample_bytree': [0.8, 1.0],  # Proportion des colonnes utilisées pour entraîner chaque arbre\n",
    "    \"learning_rate\": (0.05, 0.10, 0.15),\n",
    "}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:23:35.840435Z",
     "iopub.status.busy": "2024-06-18T18:23:35.840052Z",
     "iopub.status.idle": "2024-06-18T20:25:47.286910Z",
     "shell.execute_reply": "2024-06-18T20:25:47.285537Z",
     "shell.execute_reply.started": "2024-06-18T18:23:35.840402Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_grid, time_grid, best_model_grid = Grid(XGBClassifier(), param=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T20:25:47.289922Z",
     "iopub.status.busy": "2024-06-18T20:25:47.289407Z",
     "iopub.status.idle": "2024-06-18T20:25:47.323598Z",
     "shell.execute_reply": "2024-06-18T20:25:47.322289Z",
     "shell.execute_reply.started": "2024-06-18T20:25:47.289848Z"
    }
   },
   "outputs": [],
   "source": [
    "df_metric_grid = metric(pred_grid, \"XGBClassifier\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T20:25:47.327346Z",
     "iopub.status.busy": "2024-06-18T20:25:47.326015Z",
     "iopub.status.idle": "2024-06-18T20:25:47.684398Z",
     "shell.execute_reply": "2024-06-18T20:25:47.682876Z",
     "shell.execute_reply.started": "2024-06-18T20:25:47.327252Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_plot(df_metric_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T20:25:47.686306Z",
     "iopub.status.busy": "2024-06-18T20:25:47.685923Z",
     "iopub.status.idle": "2024-06-18T20:25:47.958063Z",
     "shell.execute_reply": "2024-06-18T20:25:47.956816Z",
     "shell.execute_reply.started": "2024-06-18T20:25:47.686274Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_time({type(best_model_grid).__name__:time_grid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T20:25:47.959964Z",
     "iopub.status.busy": "2024-06-18T20:25:47.959525Z",
     "iopub.status.idle": "2024-06-18T20:25:48.058289Z",
     "shell.execute_reply": "2024-06-18T20:25:48.057127Z",
     "shell.execute_reply.started": "2024-06-18T20:25:47.959928Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model_grid.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T20:45:46.194006Z",
     "iopub.status.busy": "2024-06-18T20:45:46.193542Z",
     "iopub.status.idle": "2024-06-18T20:45:46.199453Z",
     "shell.execute_reply": "2024-06-18T20:45:46.198251Z",
     "shell.execute_reply.started": "2024-06-18T20:45:46.193970Z"
    }
   },
   "outputs": [],
   "source": [
    "model_filename = \"XGBClassifier.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T20:45:48.413485Z",
     "iopub.status.busy": "2024-06-18T20:45:48.413074Z",
     "iopub.status.idle": "2024-06-18T20:45:48.437467Z",
     "shell.execute_reply": "2024-06-18T20:45:48.435958Z",
     "shell.execute_reply.started": "2024-06-18T20:45:48.413452Z"
    }
   },
   "outputs": [],
   "source": [
    "#Enregistrement des modèles préentrainé :\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(best_model_grid, model_file)\n",
    "    print(f'{colored(\"XGBClassifier\",\"blue\")} enregistré sous {colored(model_filename,\"green\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T20:45:52.232011Z",
     "iopub.status.busy": "2024-06-18T20:45:52.231567Z",
     "iopub.status.idle": "2024-06-18T20:45:52.709231Z",
     "shell.execute_reply": "2024-06-18T20:45:52.707971Z",
     "shell.execute_reply.started": "2024-06-18T20:45:52.231974Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_data = new_prediction(best_model_grid, df_test)\n",
    "submission_data.to_csv(\"XGBC_GRID_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Après soumission du modèle : Résultat 0.80248\n",
    "### Nous avons légèrement amélioré le modèle"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8710574,
     "sourceId": 73290,
     "sourceType": "competition"
    },
    {
     "datasetId": 5187381,
     "sourceId": 8658546,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
