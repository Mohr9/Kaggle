{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffce846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, validation_curve, cross_val_score\n",
    "\n",
    "#modelisation\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb9da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = r'D:/Kaggle_competition/01_Spaceship_titanic'\n",
    "p2 = os.listdir(str(p1+\"/\"+os.listdir(p1)[0]))[0]\n",
    "path =str(p1+\"/\"+os.listdir(p1)[0])+'/'+p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb8081",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path, index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5dc6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=\"index\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c7b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = df.drop(\"Transported\", axis = 1), df[\"Transported\"]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c62b103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93f3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui permet d'entrainer un modèle et de récupérer les prédiction\n",
    "def train_model(model):\n",
    "    model.fit(X_train,y_train)\n",
    "    yp = model.predict(X_test)\n",
    "    return yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae8732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction permettant de récupérer un dataframe contenant les metrics pour un modèle donné :\n",
    "def metric(pred, model_name):\n",
    "    f1 = f1_score(y_true=y_test,y_pred=pred)\n",
    "    acc = accuracy_score(y_true=y_test,y_pred=pred)\n",
    "    rec = recall_score(y_true=y_test,y_pred=pred)\n",
    "    prec = precision_score(y_true=y_test,y_pred=pred)\n",
    "    ind = [\"F1\",\"Accuracy\",\"Recall\",\"Precision\"]\n",
    "    serie = pd.Series([f1,acc,rec,prec], name = str(model_name), index=ind)\n",
    "    return pd.DataFrame(serie)#, index=ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca3954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour merge les dataframe :\n",
    "def merge(df1, df2):\n",
    "    return pd.merge(df1, df2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab61d836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf(pred):\n",
    "    cf = confusion_matrix(y_true=y_test, y_pred=pred)\n",
    "    ax = sns.heatmap(cf, annot = True, linewidths=0.8, linecolor=\"black\", fmt = \".0f\",cbar=False, cmap = \"Blues\")\n",
    "    ax.set_xlabel('Prédictions')\n",
    "    ax.set_ylabel('Valeurs réelles')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_c(model):\n",
    "# Obtention des scores d'apprentissage et de validation pour différentes tailles d'ensemble d'entraînement\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, X_train, y_train,\n",
    "                                                            train_sizes=np.linspace(0.1, 1.0, 10), cv=5)\n",
    "\n",
    "# Calcul des scores moyens pour l'apprentissage et la validation\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# Tracer les courbes d'apprentissage\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(train_sizes, train_scores_mean, label='Score d\\'entraînement moyen')\n",
    "    plt.plot(train_sizes, test_scores_mean, label='Score de validation moyen')\n",
    "    plt.xlabel('Taille de l\\'ensemble d\\'entraînement')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Courbes d\\'apprentissage')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3807e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recuperation des prediction du dummy :\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\",random_state=42)\n",
    "yp_dummy = train_model(dummy)\n",
    "#Création du dataframe contenant les metrics de dummy :\n",
    "df_dummy = metric(yp_dummy, \"Dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c017ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf(ypred_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f28013",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_c(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a734303b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(random_state=42)\n",
    "lr = LogisticRegression(random_state=42)\n",
    "sgdc = SGDClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c2934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3396a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recuperation des prediction du dummy :\n",
    "yp_svc = train_model(svc)\n",
    "#Création du dataframe contenant les metrics de dummy :\n",
    "df_svc = metric(yp_svc, \"SVC\")\n",
    "#Fusion des resultats obtenu avec dummy et svc :\n",
    "merged_metrics = merge(df_dummy, df_svc)\n",
    "cf(yp_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_c(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec7fe99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1b4b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recuperation des prediction  :\n",
    "yp_lr = train_model(lr)\n",
    "#Création du dataframe contenant les metrics  :\n",
    "df_lr = metric(yp_lr, \"LogisticRegression\")\n",
    "#Fusion des resultats obtenu avec le précédent merge :\n",
    "merged_metrics = merge(merged_metrics, df_lr)\n",
    "cf(yp_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_c(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bded32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recuperation des prediction  :\n",
    "yp_sgdc = train_model(sgdc)\n",
    "#Création du dataframe contenant les metrics  :\n",
    "df_sgdc = metric(yp_sgdc, \"SGDClassifier\")\n",
    "#Fusion des resultats obtenu avec le précédent merge :\n",
    "merged_metrics = merge(merged_metrics, df_sgdc)\n",
    "cf(yp_sgdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0023f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_c(sgdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294cd3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20079fc3",
   "metadata": {},
   "source": [
    "#### Cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e63dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(svc, X_train,y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a088e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
